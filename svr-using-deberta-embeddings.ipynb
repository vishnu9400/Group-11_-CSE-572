{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Acknowledge\n","I translated the amazing notebook from @Chris Deotte that you can check in here ([RAPIDS SVR](https://www.kaggle.com/code/cdeotte/rapids-svr-cv-0-450-lb-0-44x)) to learn and understand better how this works. If it helps, good!"]},{"cell_type":"markdown","metadata":{},"source":["# Load Libraries and Data"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-11-09T03:00:26.993100Z","iopub.status.busy":"2023-11-09T03:00:26.992819Z","iopub.status.idle":"2023-11-09T03:00:27.004110Z","shell.execute_reply":"2023-11-09T03:00:27.003044Z","shell.execute_reply.started":"2023-11-09T03:00:26.993073Z"},"trusted":true},"outputs":[],"source":["import numpy as np \n","import pandas as pd \n","import os, gc, re, warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T03:00:27.005976Z","iopub.status.busy":"2023-11-09T03:00:27.005676Z","iopub.status.idle":"2023-11-09T03:00:27.149040Z","shell.execute_reply":"2023-11-09T03:00:27.148115Z","shell.execute_reply.started":"2023-11-09T03:00:27.005950Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>prompt_question</th>\n","      <th>prompt_title</th>\n","      <th>prompt_text</th>\n","      <th>text</th>\n","      <th>content</th>\n","      <th>wording</th>\n","      <th>src</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Summarize at least 3 elements of an ideal trag...</td>\n","      <td>On Tragedy</td>\n","      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n","      <td>1 element of an ideal tragedy is that it shoul...</td>\n","      <td>-0.210614</td>\n","      <td>-0.471415</td>\n","      <td>train</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Summarize at least 3 elements of an ideal trag...</td>\n","      <td>On Tragedy</td>\n","      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n","      <td>The three elements of an ideal tragedy are:  H...</td>\n","      <td>-0.970237</td>\n","      <td>-0.417058</td>\n","      <td>train</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Summarize at least 3 elements of an ideal trag...</td>\n","      <td>On Tragedy</td>\n","      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n","      <td>Aristotle states that an ideal tragedy should ...</td>\n","      <td>-0.387791</td>\n","      <td>-0.584181</td>\n","      <td>train</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Summarize at least 3 elements of an ideal trag...</td>\n","      <td>On Tragedy</td>\n","      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n","      <td>One element of an Ideal tragedy is having a co...</td>\n","      <td>0.088882</td>\n","      <td>-0.594710</td>\n","      <td>train</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Summarize at least 3 elements of an ideal trag...</td>\n","      <td>On Tragedy</td>\n","      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n","      <td>The 3 ideal of tragedy is how complex you need...</td>\n","      <td>-0.687288</td>\n","      <td>-0.460886</td>\n","      <td>train</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                     prompt_question prompt_title  \\\n","0  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n","1  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n","2  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n","3  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n","4  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n","\n","                                         prompt_text  \\\n","0  Chapter 13 \\r\\nAs the sequel to what has alrea...   \n","1  Chapter 13 \\r\\nAs the sequel to what has alrea...   \n","2  Chapter 13 \\r\\nAs the sequel to what has alrea...   \n","3  Chapter 13 \\r\\nAs the sequel to what has alrea...   \n","4  Chapter 13 \\r\\nAs the sequel to what has alrea...   \n","\n","                                                text   content   wording  \\\n","0  1 element of an ideal tragedy is that it shoul... -0.210614 -0.471415   \n","1  The three elements of an ideal tragedy are:  H... -0.970237 -0.417058   \n","2  Aristotle states that an ideal tragedy should ... -0.387791 -0.584181   \n","3  One element of an Ideal tragedy is having a co...  0.088882 -0.594710   \n","4  The 3 ideal of tragedy is how complex you need... -0.687288 -0.460886   \n","\n","     src  \n","0  train  \n","1  train  \n","2  train  \n","3  train  \n","4  train  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["dftr_pro = pd.read_csv(\"/content/commonlit-evaluate-student-summaries/prompts_train.csv\")\n","dftr_sum = pd.read_csv(\"/content/commonlit-evaluate-student-summaries/summaries_train.csv\")\n","dftr = dftr_pro.merge(dftr_sum , on = \"prompt_id\")\n","dftr.drop([\"prompt_id\" , \"student_id\"] , axis = 1 , inplace = True)\n","dftr[\"src\"]=\"train\"\n","dftr.head()"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T03:00:27.150282Z","iopub.status.busy":"2023-11-09T03:00:27.149999Z","iopub.status.idle":"2023-11-09T03:00:27.177279Z","shell.execute_reply":"2023-11-09T03:00:27.176410Z","shell.execute_reply.started":"2023-11-09T03:00:27.150256Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>prompt_id</th>\n","      <th>prompt_question</th>\n","      <th>prompt_title</th>\n","      <th>prompt_text</th>\n","      <th>student_id</th>\n","      <th>text</th>\n","      <th>src</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>abc123</td>\n","      <td>Summarize...</td>\n","      <td>Example Title 1</td>\n","      <td>Heading\\nText...</td>\n","      <td>000000ffffff</td>\n","      <td>Example text 1</td>\n","      <td>test</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>abc123</td>\n","      <td>Summarize...</td>\n","      <td>Example Title 1</td>\n","      <td>Heading\\nText...</td>\n","      <td>222222cccccc</td>\n","      <td>Example text 3</td>\n","      <td>test</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>def789</td>\n","      <td>Summarize...</td>\n","      <td>Example Title 2</td>\n","      <td>Heading\\nText...</td>\n","      <td>111111eeeeee</td>\n","      <td>Example text 2</td>\n","      <td>test</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>def789</td>\n","      <td>Summarize...</td>\n","      <td>Example Title 2</td>\n","      <td>Heading\\nText...</td>\n","      <td>333333dddddd</td>\n","      <td>Example text 4</td>\n","      <td>test</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  prompt_id prompt_question     prompt_title       prompt_text    student_id  \\\n","0    abc123    Summarize...  Example Title 1  Heading\\nText...  000000ffffff   \n","1    abc123    Summarize...  Example Title 1  Heading\\nText...  222222cccccc   \n","2    def789    Summarize...  Example Title 2  Heading\\nText...  111111eeeeee   \n","3    def789    Summarize...  Example Title 2  Heading\\nText...  333333dddddd   \n","\n","             text   src  \n","0  Example text 1  test  \n","1  Example text 3  test  \n","2  Example text 2  test  \n","3  Example text 4  test  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["dfte_pro = pd.read_csv(\"/content/commonlit-evaluate-student-summaries/prompts_test.csv\")\n","dfte_sum = pd.read_csv(\"/content/commonlit-evaluate-student-summaries/summaries_test.csv\")\n","dfte = dfte_pro.merge(dfte_sum , on = \"prompt_id\")\n","dfte[\"src\"]=\"test\" \n","dfte.head()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T03:00:27.179508Z","iopub.status.busy":"2023-11-09T03:00:27.179202Z","iopub.status.idle":"2023-11-09T03:00:27.183726Z","shell.execute_reply":"2023-11-09T03:00:27.182737Z","shell.execute_reply.started":"2023-11-09T03:00:27.179482Z"},"trusted":true},"outputs":[],"source":["target_cols = ['content', 'wording']"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T03:00:27.185167Z","iopub.status.busy":"2023-11-09T03:00:27.184891Z","iopub.status.idle":"2023-11-09T03:00:28.572887Z","shell.execute_reply":"2023-11-09T03:00:28.571804Z","shell.execute_reply.started":"2023-11-09T03:00:27.185142Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train samples per fold:\n"]},{"data":{"text/plain":["13.0    359\n","15.0    359\n","19.0    359\n","14.0    359\n","3.0     359\n","2.0     358\n","1.0     358\n","16.0    358\n","17.0    358\n","12.0    358\n","18.0    358\n","6.0     358\n","11.0    358\n","7.0     358\n","10.0    358\n","0.0     358\n","8.0     358\n","9.0     358\n","5.0     358\n","4.0     358\n","Name: FOLD, dtype: int64"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["import sys\n","sys.path.append(\"../input/iterativestratification\")\n","from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n","FOLDS = 20\n","skf = MultilabelStratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)\n","for i,(train_index, val_index) in enumerate(skf.split(dftr,dftr[target_cols])):\n","    dftr.loc[val_index,'FOLD'] = i\n","print('Train samples per fold:')\n","dftr.FOLD.value_counts()"]},{"cell_type":"markdown","metadata":{},"source":["# Generate Embeddings"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T03:00:28.574545Z","iopub.status.busy":"2023-11-09T03:00:28.574172Z","iopub.status.idle":"2023-11-09T03:00:33.517179Z","shell.execute_reply":"2023-11-09T03:00:33.516244Z","shell.execute_reply.started":"2023-11-09T03:00:28.574511Z"},"trusted":true},"outputs":[],"source":["from transformers import AutoModel, AutoTokenizer\n","import torch\n","import torch.nn.functional as F\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T03:00:33.519289Z","iopub.status.busy":"2023-11-09T03:00:33.518690Z","iopub.status.idle":"2023-11-09T03:00:33.526736Z","shell.execute_reply":"2023-11-09T03:00:33.524841Z","shell.execute_reply.started":"2023-11-09T03:00:33.519254Z"},"trusted":true},"outputs":[],"source":["def mean_pooling(model_output, attention_mask):\n","    # Create the token embeddings\n","    token_embeddings = model_output.last_hidden_state.detach().cpu()\n","    input_mask_expanded = (\n","        attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n","    )\n","    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(\n","        input_mask_expanded.sum(1), min=1e-9\n","    )"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T03:00:33.528143Z","iopub.status.busy":"2023-11-09T03:00:33.527868Z","iopub.status.idle":"2023-11-09T03:00:33.539899Z","shell.execute_reply":"2023-11-09T03:00:33.538855Z","shell.execute_reply.started":"2023-11-09T03:00:33.528118Z"},"trusted":true},"outputs":[],"source":["BATCH_SIZE = 4"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T03:00:33.543701Z","iopub.status.busy":"2023-11-09T03:00:33.543425Z","iopub.status.idle":"2023-11-09T03:00:33.554116Z","shell.execute_reply":"2023-11-09T03:00:33.553229Z","shell.execute_reply.started":"2023-11-09T03:00:33.543664Z"},"trusted":true},"outputs":[],"source":["# Create a class for the embedded dataset\n","\n","class EmbedDataset(torch.utils.data.Dataset):\n","    def __init__(self,df):\n","        self.df = df.reset_index(drop=True)\n","    def __len__(self):\n","        return len(self.df)\n","    def __getitem__(self,idx):\n","        text = self.df.loc[idx, \"text\"] # self.df.loc[idx, \"prompt_question\"] + self.df.loc[idx, \"prompt_title\"] + self.df.loc[idx, \"prompt_text\"] +  self.df.loc[idx,\"full_text\"]\n","        tokens = tokenizer(\n","                text,\n","                None,\n","                add_special_tokens=True,\n","                padding='max_length',\n","                truncation=True,\n","                max_length=MAX_LEN,return_tensors=\"pt\")\n","        tokens = {k:v.squeeze(0) for k,v in tokens.items()}\n","        return tokens\n","\n","ds_tr = EmbedDataset(dftr)\n","embed_dataloader_tr = torch.utils.data.DataLoader(ds_tr,\\\n","                        batch_size=BATCH_SIZE,\\\n","                        shuffle=False)\n","ds_te = EmbedDataset(dfte)\n","embed_dataloader_te = torch.utils.data.DataLoader(ds_te,\\\n","                        batch_size=BATCH_SIZE,\\\n","                        shuffle=False)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T03:00:33.555640Z","iopub.status.busy":"2023-11-09T03:00:33.555346Z","iopub.status.idle":"2023-11-09T03:00:33.568100Z","shell.execute_reply":"2023-11-09T03:00:33.567414Z","shell.execute_reply.started":"2023-11-09T03:00:33.555616Z"},"trusted":true},"outputs":[],"source":["tokenizer = None\n","MAX_LEN = 512\n","\n","def get_embeddings(MODEL_NM='', MAX=640, BATCH_SIZE=4, verbose=True, ex_verbose=False):\n","    global tokenizer, MAX_LEN\n","    DEVICE=\"cuda\"\n","    model = AutoModel.from_pretrained( MODEL_NM )\n","    tokenizer = AutoTokenizer.from_pretrained( MODEL_NM )\n","    MAX_LEN = MAX\n","    \n","    model = model.to(DEVICE)\n","    model.eval()\n","    all_train_text_feats = []\n","    for batch in tqdm(embed_dataloader_tr,total=len(embed_dataloader_tr)):\n","        input_ids = batch[\"input_ids\"].to(DEVICE)\n","        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n","        with torch.no_grad():\n","            model_output = model(input_ids=input_ids,attention_mask=attention_mask)\n","        sentence_embeddings = mean_pooling(model_output, attention_mask.detach().cpu())\n","        # Normalize the embeddings\n","        sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n","        sentence_embeddings = sentence_embeddings.squeeze(0).detach().cpu().numpy()\n","        if ex_verbose:\n","            print(sentence_embeddings.shape)\n","        if len(sentence_embeddings.shape) == 1: # janky workaround\n","            continue\n","        all_train_text_feats.extend(sentence_embeddings)\n","    \n","    all_train_text_feats = np.array(all_train_text_feats)\n","        \n","    if verbose:\n","        print('Train embeddings shape', all_train_text_feats.shape)\n","      \n","    te_text_feats = []\n","    for batch in tqdm(embed_dataloader_te,total=len(embed_dataloader_te)):\n","        input_ids = batch[\"input_ids\"].to(DEVICE)\n","        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n","        with torch.no_grad():\n","            model_output = model(input_ids=input_ids,attention_mask=attention_mask)\n","        sentence_embeddings = mean_pooling(model_output, attention_mask.detach().cpu())\n","        # Normalize the embeddings\n","        sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n","        sentence_embeddings = sentence_embeddings.squeeze(0).detach().cpu().numpy()\n","        te_text_feats.extend(sentence_embeddings)\n","    te_text_feats = np.array(te_text_feats)\n","    if verbose:\n","        print('Test embeddings shape',te_text_feats.shape)\n","      \n","    return all_train_text_feats, te_text_feats"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T03:00:33.569498Z","iopub.status.busy":"2023-11-09T03:00:33.569087Z","iopub.status.idle":"2023-11-09T03:04:44.672160Z","shell.execute_reply":"2023-11-09T03:04:44.671199Z","shell.execute_reply.started":"2023-11-09T03:00:33.569473Z"},"scrolled":true,"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at ../input/huggingface-deberta-variants/deberta-base/deberta-base were not used when initializing DebertaModel: ['config', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","100%|██████████| 1792/1792 [03:49<00:00,  7.82it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Train embeddings shape (7164, 768)\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  7.80it/s]"]},{"name":"stdout","output_type":"stream","text":["Test embeddings shape (4, 768)\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["MODEL_NM = '../input/huggingface-deberta-variants/deberta-base/deberta-base'\n","all_train_text_feats, te_text_feats = get_embeddings(MODEL_NM, MAX=512)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T03:04:44.674175Z","iopub.status.busy":"2023-11-09T03:04:44.673601Z","iopub.status.idle":"2023-11-09T03:15:49.622424Z","shell.execute_reply":"2023-11-09T03:15:49.621639Z","shell.execute_reply.started":"2023-11-09T03:04:44.674139Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at ../input/deberta-v3-large/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","100%|██████████| 1792/1792 [10:48<00:00,  2.76it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Train embeddings shape (7164, 1024)\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  2.76it/s]"]},{"name":"stdout","output_type":"stream","text":["Test embeddings shape (4, 1024)\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["MODEL_NM = '../input/deberta-v3-large/deberta-v3-large'\n","all_train_text_feats2, te_text_feats2 = get_embeddings(MODEL_NM, MAX=512)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T03:15:49.624595Z","iopub.status.busy":"2023-11-09T03:15:49.623938Z","iopub.status.idle":"2023-11-09T03:27:32.521253Z","shell.execute_reply":"2023-11-09T03:27:32.520212Z","shell.execute_reply.started":"2023-11-09T03:15:49.624563Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at ../input/huggingface-deberta-variants/deberta-large/deberta-large were not used when initializing DebertaModel: ['config', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","100%|██████████| 1792/1792 [11:20<00:00,  2.63it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Train embeddings shape (7164, 1024)\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  2.64it/s]"]},{"name":"stdout","output_type":"stream","text":["Test embeddings shape (4, 1024)\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["MODEL_NM = '../input/huggingface-deberta-variants/deberta-large/deberta-large'\n","all_train_text_feats3, te_text_feats3 = get_embeddings(MODEL_NM, MAX=512)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T03:27:32.523710Z","iopub.status.busy":"2023-11-09T03:27:32.523103Z","iopub.status.idle":"2023-11-09T03:39:15.665565Z","shell.execute_reply":"2023-11-09T03:39:15.664678Z","shell.execute_reply.started":"2023-11-09T03:27:32.523670Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at ../input/huggingface-deberta-variants/deberta-large-mnli/deberta-large-mnli were not used when initializing DebertaModel: ['pooler.dense.bias', 'pooler.dense.weight', 'config', 'classifier.weight', 'classifier.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","100%|██████████| 1792/1792 [11:21<00:00,  2.63it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Train embeddings shape (7164, 1024)\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  2.64it/s]"]},{"name":"stdout","output_type":"stream","text":["Test embeddings shape (4, 1024)\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["MODEL_NM = '../input/huggingface-deberta-variants/deberta-large-mnli/deberta-large-mnli'\n","all_train_text_feats4, te_text_feats4 = get_embeddings(MODEL_NM, MAX=512)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T03:39:15.667468Z","iopub.status.busy":"2023-11-09T03:39:15.667143Z","iopub.status.idle":"2023-11-09T04:02:05.109614Z","shell.execute_reply":"2023-11-09T04:02:05.108720Z","shell.execute_reply.started":"2023-11-09T03:39:15.667440Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at ../input/huggingface-deberta-variants/deberta-xlarge/deberta-xlarge were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","100%|██████████| 1792/1792 [22:23<00:00,  1.33it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Train embeddings shape (7164, 1024)\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  1.34it/s]"]},{"name":"stdout","output_type":"stream","text":["Test embeddings shape (4, 1024)\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["MODEL_NM = '../input/huggingface-deberta-variants/deberta-xlarge/deberta-xlarge'\n","all_train_text_feats5, te_text_feats5 = get_embeddings(MODEL_NM, MAX=512)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T04:02:05.111701Z","iopub.status.busy":"2023-11-09T04:02:05.111301Z","iopub.status.idle":"2023-11-09T04:02:05.422833Z","shell.execute_reply":"2023-11-09T04:02:05.421923Z","shell.execute_reply.started":"2023-11-09T04:02:05.111657Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Our concatenated embeddings have shape (7164, 4864)\n"]}],"source":["all_train_text_feats = np.concatenate([all_train_text_feats, all_train_text_feats2,\n","                                       all_train_text_feats3, all_train_text_feats4,\n","                                       all_train_text_feats5], axis=1)\n","te_text_feats = np.concatenate([te_text_feats, te_text_feats2,\n","                                te_text_feats3, te_text_feats4,\n","                               te_text_feats5], axis=1)\n","# delete other embeddings if used\n","del all_train_text_feats2, te_text_feats2\n","del all_train_text_feats3, te_text_feats3\n","del all_train_text_feats4, te_text_feats4\n","del all_train_text_feats5, te_text_feats5\n","gc.collect()\n","print('Our concatenated embeddings have shape', all_train_text_feats.shape )"]},{"cell_type":"markdown","metadata":{},"source":["# Train SVR"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T04:02:05.424968Z","iopub.status.busy":"2023-11-09T04:02:05.424144Z","iopub.status.idle":"2023-11-09T04:02:10.076324Z","shell.execute_reply":"2023-11-09T04:02:10.075577Z","shell.execute_reply.started":"2023-11-09T04:02:05.424931Z"},"trusted":true},"outputs":[],"source":["from cuml.svm import SVR\n","#from sklearn.svm import SVR\n","#import cuml\n","import cudf\n","import cupy as cp\n","#print(\"Checking for cuml\", cuml.__version__)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T04:02:10.077728Z","iopub.status.busy":"2023-11-09T04:02:10.077443Z","iopub.status.idle":"2023-11-09T04:02:10.083310Z","shell.execute_reply":"2023-11-09T04:02:10.082458Z","shell.execute_reply.started":"2023-11-09T04:02:10.077703Z"},"trusted":true},"outputs":[],"source":["# The metric\n","from sklearn.metrics import mean_squared_error\n","\n","preds = []\n","scores = []\n","\n","def comp_score(y_true, y_pred):\n","    rmse_scores = []\n","    for i in range(len(target_cols)):\n","        rmse_scores.append(np.sqrt(mean_squared_error(y_true[:,i], y_pred[:,i])))\n","    return np.mean(rmse_scores)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T04:02:10.084538Z","iopub.status.busy":"2023-11-09T04:02:10.084268Z","iopub.status.idle":"2023-11-09T04:02:10.094939Z","shell.execute_reply":"2023-11-09T04:02:10.094159Z","shell.execute_reply.started":"2023-11-09T04:02:10.084514Z"},"trusted":true},"outputs":[],"source":["test_preds = np.zeros((len(te_text_feats),2))"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T04:02:10.096317Z","iopub.status.busy":"2023-11-09T04:02:10.096030Z","iopub.status.idle":"2023-11-09T04:02:10.106339Z","shell.execute_reply":"2023-11-09T04:02:10.105573Z","shell.execute_reply.started":"2023-11-09T04:02:10.096292Z"},"trusted":true},"outputs":[],"source":["dftr.drop(dftr.index[-1], inplace=True)"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T04:02:10.107869Z","iopub.status.busy":"2023-11-09T04:02:10.107515Z","iopub.status.idle":"2023-11-09T04:02:29.407920Z","shell.execute_reply":"2023-11-09T04:02:29.406946Z","shell.execute_reply.started":"2023-11-09T04:02:10.107835Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/20 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["content , wording , "]},{"name":"stderr","output_type":"stream","text":["  5%|▌         | 1/20 [00:07<02:21,  7.44s/it]"]},{"name":"stdout","output_type":"stream","text":["\n","Fold : 0 RSME score: 0.4857991696412925\n","content , wording , "]},{"name":"stderr","output_type":"stream","text":[" 10%|█         | 2/20 [00:08<01:01,  3.43s/it]"]},{"name":"stdout","output_type":"stream","text":["\n","Fold : 1 RSME score: 0.5135170700748948\n","content , wording , "]},{"name":"stderr","output_type":"stream","text":[" 15%|█▌        | 3/20 [00:08<00:36,  2.14s/it]"]},{"name":"stdout","output_type":"stream","text":["\n","Fold : 2 RSME score: 0.5141208581441621\n","content , wording , "]},{"name":"stderr","output_type":"stream","text":[" 20%|██        | 4/20 [00:09<00:24,  1.54s/it]"]},{"name":"stdout","output_type":"stream","text":["\n","Fold : 3 RSME score: 0.512510632118025\n","content , wording , "]},{"name":"stderr","output_type":"stream","text":[" 25%|██▌       | 5/20 [00:09<00:18,  1.22s/it]"]},{"name":"stdout","output_type":"stream","text":["\n","Fold : 4 RSME score: 0.4995725260801155\n","content , wording , "]},{"name":"stderr","output_type":"stream","text":[" 30%|███       | 6/20 [00:10<00:14,  1.01s/it]"]},{"name":"stdout","output_type":"stream","text":["\n","Fold : 5 RSME score: 0.5275545503212785\n","content , wording , "]},{"name":"stderr","output_type":"stream","text":[" 35%|███▌      | 7/20 [00:11<00:11,  1.14it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Fold : 6 RSME score: 0.5014564481671738\n","content , wording , "]},{"name":"stderr","output_type":"stream","text":[" 40%|████      | 8/20 [00:11<00:09,  1.25it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Fold : 7 RSME score: 0.5007608545850175\n","content , wording , "]},{"name":"stderr","output_type":"stream","text":[" 45%|████▌     | 9/20 [00:12<00:08,  1.35it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Fold : 8 RSME score: 0.5381253705089003\n","content , wording , "]},{"name":"stderr","output_type":"stream","text":[" 50%|█████     | 10/20 [00:13<00:07,  1.42it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Fold : 9 RSME score: 0.49038674922258235\n","content , wording , "]},{"name":"stderr","output_type":"stream","text":[" 55%|█████▌    | 11/20 [00:13<00:06,  1.47it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Fold : 10 RSME score: 0.5089160499475687\n","content , wording , "]},{"name":"stderr","output_type":"stream","text":[" 60%|██████    | 12/20 [00:14<00:05,  1.51it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Fold : 11 RSME score: 0.4351359432763593\n","content , wording , "]},{"name":"stderr","output_type":"stream","text":[" 65%|██████▌   | 13/20 [00:14<00:04,  1.55it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Fold : 12 RSME score: 0.5196545490533362\n","content , wording , "]},{"name":"stderr","output_type":"stream","text":[" 70%|███████   | 14/20 [00:15<00:03,  1.55it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Fold : 13 RSME score: 0.4891641207578526\n","content , wording , "]},{"name":"stderr","output_type":"stream","text":[" 75%|███████▌  | 15/20 [00:16<00:03,  1.56it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Fold : 14 RSME score: 0.48870907099812777\n","content , wording , "]},{"name":"stderr","output_type":"stream","text":[" 80%|████████  | 16/20 [00:16<00:02,  1.57it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Fold : 15 RSME score: 0.49096830423602417\n","content , wording , "]},{"name":"stderr","output_type":"stream","text":[" 85%|████████▌ | 17/20 [00:17<00:01,  1.56it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Fold : 16 RSME score: 0.47861781393627245\n","content , wording , "]},{"name":"stderr","output_type":"stream","text":[" 90%|█████████ | 18/20 [00:18<00:01,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Fold : 17 RSME score: 0.5030517609130829\n","content , wording , "]},{"name":"stderr","output_type":"stream","text":[" 95%|█████████▌| 19/20 [00:18<00:00,  1.60it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Fold : 18 RSME score: 0.4942121705438145\n","content , wording , "]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 20/20 [00:19<00:00,  1.04it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Fold : 19 RSME score: 0.5514226348349174\n","Overall CV RSME = 0.50218283236804\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["for fold in tqdm(range(FOLDS),total=FOLDS):\n","#for fold in range(FOLDS):\n","#    print('#'*25)\n","#    print('### Fold',fold+1)\n","#    print('#'*25)\n","    \n","    dftr_ = dftr[dftr[\"FOLD\"]!=fold]\n","    dfev_ = dftr[dftr[\"FOLD\"]==fold]\n","    \n","    tr_text_feats = all_train_text_feats[list(dftr_.index),:]\n","    ev_text_feats = all_train_text_feats[list(dfev_.index),:]\n","    \n","    ev_preds = np.zeros((len(ev_text_feats),2))\n","    test_preds = np.zeros((len(te_text_feats),2))\n","    for i,t in enumerate(target_cols):\n","        print(t,', ',end='')\n","        clf = SVR(C=1)\n","        clf.fit(tr_text_feats, dftr_[t].values)\n","        ev_preds[:,i] = clf.predict(ev_text_feats)\n","        test_preds[:,i] = clf.predict(te_text_feats)\n","    print()\n","    score = comp_score(dfev_[target_cols].values,ev_preds)\n","    scores.append(score)\n","    print(\"Fold : {} RSME score: {}\".format(fold,score))\n","    preds.append(test_preds)\n","    \n","#print('#'*25)\n","print('Overall CV RSME =',np.mean(scores))"]},{"cell_type":"markdown","metadata":{},"source":["# prediction"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T04:02:29.409868Z","iopub.status.busy":"2023-11-09T04:02:29.409243Z","iopub.status.idle":"2023-11-09T04:02:29.427099Z","shell.execute_reply":"2023-11-09T04:02:29.426265Z","shell.execute_reply.started":"2023-11-09T04:02:29.409832Z"},"trusted":true},"outputs":[],"source":["sub = dfte.copy()\n","sub.loc[:,target_cols] = np.array(test_preds) #,weights=[1/s for s in scores]\n","sub_columns = pd.read_csv(\"/content/commonlit-evaluate-student-summaries/sample_submission.csv\").columns\n","sub = sub[sub_columns]"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":6201832,"sourceId":53482,"sourceType":"competition"},{"datasetId":1369875,"sourceId":3201311,"sourceType":"datasetVersion"},{"datasetId":1993148,"sourceId":3293072,"sourceType":"datasetVersion"},{"datasetId":930977,"sourceId":6901541,"sourceType":"datasetVersion"}],"dockerImageVersionId":30528,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
